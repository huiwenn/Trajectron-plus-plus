{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7afad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "#from argoverse.map_representation.map_api import ArgoverseMap\n",
    "import torch\n",
    "from torch import nn, optim, utils\n",
    "from torch.utils.data import IterableDataset, DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db2a6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting orjson\n",
      "  Downloading orjson-3.6.5-cp37-cp37m-manylinux_2_24_x86_64.whl (247 kB)\n",
      "     |████████████████████████████████| 247 kB 15.7 MB/s            \n",
      "\u001b[?25hInstalling collected packages: orjson\n",
      "Successfully installed orjson-3.6.5\n"
     ]
    }
   ],
   "source": [
    "!pip install orjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41779bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Environment, Scene, Node\n",
    "from utils import maybe_makedirs\n",
    "from environment import derivative_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91767a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(    'position', 'x'),\n",
       "            (    'position', 'y'),\n",
       "            (    'velocity', 'x'),\n",
       "            (    'velocity', 'y'),\n",
       "            ('acceleration', 'x'),\n",
       "            ('acceleration', 'y')],\n",
       "           )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_columns = pd.MultiIndex.from_product([['position', 'velocity', 'acceleration'], ['x', 'y']])\n",
    "data_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7809fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_max_time = 100\n",
    "pred_indices = [2, 3]\n",
    "state_dim = 6\n",
    "frame_diff = 10\n",
    "desired_frame_diff = 1\n",
    "dt = 0.1\n",
    "\n",
    "standardization = {\n",
    "    'PEDESTRIAN': {\n",
    "        'position': {\n",
    "            'x': {'mean': 0, 'std': 1},\n",
    "            'y': {'mean': 0, 'std': 1}\n",
    "        },\n",
    "        'velocity': {\n",
    "            'x': {'mean': 0, 'std': 2},\n",
    "            'y': {'mean': 0, 'std': 2}\n",
    "        },\n",
    "        'acceleration': {\n",
    "            'x': {'mean': 0, 'std': 1},\n",
    "            'y': {'mean': 0, 'std': 1}\n",
    "        }\n",
    "    },\n",
    "    'VEHICLE': {\n",
    "        'position': {\n",
    "            'x': {'mean': 0, 'std': 80},\n",
    "            'y': {'mean': 0, 'std': 80}\n",
    "        },\n",
    "        'velocity': {\n",
    "            'x': {'mean': 0, 'std': 15},\n",
    "            'y': {'mean': 0, 'std': 15},\n",
    "            'norm': {'mean': 0, 'std': 15}\n",
    "        },\n",
    "        'acceleration': {\n",
    "            'x': {'mean': 0, 'std': 4},\n",
    "            'y': {'mean': 0, 'std': 4},\n",
    "            'norm': {'mean': 0, 'std': 4}\n",
    "        },\n",
    "        'heading': {\n",
    "            'x': {'mean': 0, 'std': 1},\n",
    "            'y': {'mean': 0, 'std': 1},\n",
    "            '°': {'mean': 0, 'std': np.pi},\n",
    "            'd°': {'mean': 0, 'std': 1}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b638ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(node_type_list=['PEDESTRIAN'], standardization=standardization)\n",
    "attention_radius = dict()\n",
    "attention_radius[(env.NodeType.PEDESTRIAN, env.NodeType.PEDESTRIAN)] = 3.0\n",
    "env.attention_radius = attention_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_source = 'eth'\n",
    "data_class = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = os.path.join('../experiments/pedestrians/raw', desired_source, data_class)\n",
    "for subdir, dirs, files in os.walk(pa):\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            input_data_dict = dict()\n",
    "            full_data_path = os.path.join(subdir, file)\n",
    "            print('At', full_data_path)\n",
    "            data = pd.read_csv(full_data_path, sep='\\t', index_col=False, header=None)\n",
    "            data.columns = ['frame_id', 'track_id', 'pos_x', 'pos_y']\n",
    "            data['frame_id'] = pd.to_numeric(data['frame_id'], downcast='integer')\n",
    "            data['track_id'] = pd.to_numeric(data['track_id'], downcast='integer')\n",
    "\n",
    "            data['frame_id'] = data['frame_id'] // 10\n",
    "\n",
    "            data['frame_id'] -= data['frame_id'].min()\n",
    "\n",
    "            data['node_type'] = 'PEDESTRIAN'\n",
    "            data['node_id'] = data['track_id'].astype(str)\n",
    "            data.sort_values('frame_id', inplace=True)\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6100342",
   "metadata": {},
   "source": [
    "# Argoverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "155c5a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " agents_train.npy\t\t    forecasting_test_v1.1.tar.gz\r\n",
      " agents_train_rotation.npy\t    forecasting_test_v1.1.tar.gz.1\r\n",
      " agents_train_small.npy\t\t    forecasting_train_v1.1.tar.gz.2\r\n",
      " agents_train_small_transi.npy\t   'preprocessing for cvae.ipynb'\r\n",
      " agents_train_transi.npy\t    preprocessing.ipynb\r\n",
      " agents_train_transi_rotation.npy   test\r\n",
      " agents_val.npy\t\t\t    test_new\r\n",
      " agents_val_rotation.npy\t    test_obs\r\n",
      " agents_val_transi.npy\t\t    train\r\n",
      " agents_val_transi_rotation.npy     train_original\r\n",
      " argoverse-api.git\t\t    val\r\n",
      " features\t\t\t    val_original\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../../argoverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4d03f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_list = glob(os.path.join('../../argoverse/val', '*'))\n",
    "np.random.shuffle(pkl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cc662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(node_type_list=['VEHICLE'], standardization=standardization)\n",
    "attention_radius = dict()\n",
    "attention_radius[(env.NodeType.PEDESTRIAN, env.NodeType.PEDESTRIAN)] = 30.0\n",
    "env.attention_radius = attention_radius\n",
    "#env.robot_type = env.NodeType.VEHICLE\n",
    "scenes = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "268314bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env_argo(pkl_list):\n",
    "    env = Environment(node_type_list=['VEHICLE'], standardization=standardization)\n",
    "    attention_radius = dict()\n",
    "    attention_radius[(env.NodeType.VEHICLE, env.NodeType.VEHICLE)] = 30.0\n",
    "    env.attention_radius = attention_radius\n",
    "    #env.robot_type = env.NodeType.VEHICLE\n",
    "    scenes = []\n",
    "\n",
    "\n",
    "    dfcolumns = ['frame_id', 'track_id', 'pos_x', 'pos_y', 'node_type', 'node_id','agent','scene_idx']\n",
    "    counter = 0\n",
    "    for pkl_path in tqdm(pkl_list):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)    \n",
    "        agent = (data['track_id0'][0] == data['agent_id']).nonzero()\n",
    "        agent = int(agent[0])\n",
    "\n",
    "        scene = data['scene_idx'][0]\n",
    "        cars = int(data['car_mask'][0].sum())\n",
    "        cardfs = []\n",
    "\n",
    "        for i in range(cars):\n",
    "            #obj = \"AGENT\" if (i==agent) else \"OTHERS\"\n",
    "            isagent = 1 if (i==agent) else 0\n",
    "            trackid = data['track_id0'][0][i][-6:]\n",
    "            nodeid = trackid\n",
    "            in_x = data['pos_2s'][0][i,:,0]\n",
    "            in_y = data['pos_2s'][0][i,:,1]\n",
    "            out_x = [data['pos'+str(j)][0][i,0] for j in range(31)]\n",
    "            out_y = [data['pos'+str(j)][0][i,1] for j in range(31)]\n",
    "            dic = {'frame_id': list(range(49)), \n",
    "                   'track_id':[trackid]*49, \n",
    "                   'pos_x': np.concatenate([in_x,out_x],axis=0).tolist(),\n",
    "                   'pos_y': np.concatenate([in_y,out_y],axis=0).tolist(),\n",
    "                   'agent':[isagent]*49,\n",
    "                  }\n",
    "\n",
    "            thiscar = pd.DataFrame.from_dict(dic)\n",
    "            cardfs.append(thiscar)\n",
    "\n",
    "        data = pd.concat(cardfs, ignore_index=True)\n",
    "        data['node_type']='VEHICLE' #'vehicle'\n",
    "        data['scene_idx'] = scene\n",
    "\n",
    "        data['track_id'] = pd.to_numeric(data['track_id'], downcast='integer')\n",
    "        data['node_id'] = data['track_id'].astype(str)\n",
    "        data.sort_values('frame_id', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        # Mean Position\n",
    "        data['pos_x'] = data['pos_x'] - data['pos_x'].mean()\n",
    "        data['pos_y'] = data['pos_y'] - data['pos_y'].mean()\n",
    "\n",
    "        max_timesteps = data['frame_id'].max()\n",
    "\n",
    "        scene = Scene(timesteps=max_timesteps+1, dt=dt, name=desired_source + \"_\" + data_class, aug_func=None) # aug_func=augment if data_class == 'train' else\n",
    "\n",
    "        for node_id in pd.unique(data['node_id']):\n",
    "\n",
    "            node_df = data[data['node_id'] == node_id]\n",
    "            assert np.all(np.diff(node_df['frame_id']) == 1)\n",
    "\n",
    "            node_values = node_df[['pos_x', 'pos_y']].values\n",
    "\n",
    "            if node_values.shape[0] < 2:\n",
    "                continue\n",
    "\n",
    "            new_first_idx = node_df['frame_id'].iloc[0]\n",
    "\n",
    "            x = node_values[:, 0]\n",
    "            y = node_values[:, 1]\n",
    "            vx = derivative_of(x, scene.dt)\n",
    "            vy = derivative_of(y, scene.dt)\n",
    "            ax = derivative_of(vx, scene.dt)\n",
    "            ay = derivative_of(vy, scene.dt)\n",
    "\n",
    "            data_dict = {('position', 'x'): x,\n",
    "                         ('position', 'y'): y,\n",
    "                         ('velocity', 'x'): vx,\n",
    "                         ('velocity', 'y'): vy,\n",
    "                         ('acceleration', 'x'): ax,\n",
    "                         ('acceleration', 'y'): ay}\n",
    "\n",
    "            node_data = pd.DataFrame(data_dict, columns=data_columns)\n",
    "            node = Node(node_type=env.NodeType.PEDESTRIAN, node_id=node_id, data=node_data)\n",
    "            node.first_timestep = new_first_idx\n",
    "\n",
    "            scene.nodes.append(node)\n",
    "\n",
    "        scenes.append(scene)\n",
    "        counter += 1\n",
    "        #     if counter > 100:\n",
    "        #         break\n",
    "        #print(f'Processed {len(scenes):.2f} scene for data class {data_class}')\n",
    "\n",
    "    env.scenes = scenes\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e4495e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39472/39472 [23:14<00:00, 28.31it/s]\n"
     ]
    }
   ],
   "source": [
    "pkl_list = glob(os.path.join('../../argoverse/val', '*'))\n",
    "np.random.shuffle(pkl_list)\n",
    "env_val = make_env_argo(pkl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f617045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../experiments/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1260fcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39472"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env_val.scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fdefc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_val = env_val.scenes[:5000]\n",
    "env_val.scenes = small_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "144bc643",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_path = os.path.join('../experiments/processed', '_'.join(['argoverse', 'val_small']) + '.pkl')\n",
    "if len(scenes) > 0:\n",
    "    with open(data_dict_path, 'wb') as f:\n",
    "        dill.dump(env_val, f, protocol=dill.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eebd9bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 205942/205942 [2:10:35<00:00, 26.28it/s]\n"
     ]
    }
   ],
   "source": [
    "pkl_list = glob(os.path.join('../../argoverse/train', '*'))\n",
    "np.random.shuffle(pkl_list)\n",
    "env_train = make_env_argo(pkl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8eefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(env_train.scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0a8f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_path = os.path.join('../experiments/processed', '_'.join(['argoverse', 'train']) + '.pkl')\n",
    "if len(scenes) > 0:\n",
    "    with open(data_dict_path, 'wb') as f:\n",
    "        dill.dump(env_train, f, protocol=dill.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f16362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1352499c",
   "metadata": {},
   "source": [
    "# Pedestrian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd94fdd",
   "metadata": {},
   "source": [
    "val and val_small are reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d2a529e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22937/22937 [02:23<00:00, 159.48it/s]\n"
     ]
    }
   ],
   "source": [
    "pkl_list = glob(os.path.join('../../pedestrian/processed/val', '*'))\n",
    "np.random.shuffle(pkl_list)\n",
    "env_val = make_env_ped(pkl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92a30528",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_path = os.path.join('../experiments/processed', '_'.join(['ped', 'val_small']) + '.pkl')\n",
    "if len(scenes) > 0:\n",
    "    with open(data_dict_path, 'wb') as f:\n",
    "        dill.dump(env_val, f, protocol=dill.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33a201bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_val = env_val.scenes[:5000]\n",
    "env_val.scenes = small_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e04edfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_path = os.path.join('../experiments/processed', '_'.join(['ped', 'val']) + '.pkl')\n",
    "if len(scenes) > 0:\n",
    "    with open(data_dict_path, 'wb') as f:\n",
    "        dill.dump(env_val, f, protocol=dill.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eeec7e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 217953/217953 [24:57<00:00, 145.57it/s]\n"
     ]
    }
   ],
   "source": [
    "pkl_list = glob(os.path.join('../../pedestrian/processed/train', '*'))\n",
    "np.random.shuffle(pkl_list)\n",
    "env_train = make_env_ped(pkl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6d14022",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_path = os.path.join('../experiments/processed', '_'.join(['ped', 'train']) + '.pkl')\n",
    "if len(scenes) > 0:\n",
    "    with open(data_dict_path, 'wb') as f:\n",
    "        dill.dump(env_train, f, protocol=dill.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a427f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc286e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "164bc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_list = pkl_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07be857c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['man_mask', 'pos_enc', 'vel_enc', 'pos0', 'vel0', 'pos1', 'vel1', 'pos2', 'vel2', 'pos3', 'vel3', 'pos4', 'vel4', 'pos5', 'vel5', 'pos6', 'vel6', 'pos7', 'vel7', 'pos8', 'vel8', 'pos9', 'vel9', 'pos10', 'vel10', 'pos11', 'vel11', 'pos12', 'vel12', 'scene_idx'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb28c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env_ped(pkl_list):\n",
    "    env = Environment(node_type_list=['PEDESTRIAN'], standardization=standardization)\n",
    "    attention_radius = dict()\n",
    "    attention_radius[(env.NodeType.PEDESTRIAN, env.NodeType.PEDESTRIAN)] = 30.0\n",
    "    env.attention_radius = attention_radius\n",
    "    #env.robot_type = env.NodeType.VEHICLE\n",
    "    scenes = []\n",
    "\n",
    "\n",
    "    dfcolumns = ['frame_id', 'track_id', 'pos_x', 'pos_y', 'node_type', 'node_id','agent','scene_idx']\n",
    "    counter = 0\n",
    "    for pkl_path in tqdm(pkl_list):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)    \n",
    "\n",
    "        scene = data['scene_idx'][0]\n",
    "        cars = int(data['man_mask'][0].sum())\n",
    "        cardfs = []\n",
    "\n",
    "        for i in range(cars):\n",
    "            #obj = \"AGENT\" if (i==agent) else \"OTHERS\"\n",
    "            isagent = 1 if (i==0) else 0\n",
    "            trackid = i\n",
    "            nodeid = trackid\n",
    "            in_x = data['pos_enc'][i,:,0]\n",
    "            in_y = data['pos_enc'][i,:,1]\n",
    "            out_x = [data['pos'+str(j)][i,0] for j in range(13)]\n",
    "            out_y = [data['pos'+str(j)][i,1] for j in range(13)]\n",
    "            dic = {'frame_id': list(range(20)), \n",
    "                   'track_id':[trackid]*20, \n",
    "                   'pos_x': np.concatenate([in_x,out_x],axis=0).tolist(),\n",
    "                   'pos_y': np.concatenate([in_y,out_y],axis=0).tolist(),\n",
    "                   'agent':[isagent]*20,\n",
    "                  }\n",
    "\n",
    "            thiscar = pd.DataFrame.from_dict(dic)\n",
    "            cardfs.append(thiscar)\n",
    "\n",
    "        data = pd.concat(cardfs, ignore_index=True)\n",
    "        data['node_type']='PEDESTRIAN' #'vehicle'\n",
    "        data['scene_idx'] = scene\n",
    "\n",
    "        data['track_id'] = pd.to_numeric(data['track_id'], downcast='integer')\n",
    "        data['node_id'] = data['track_id'].astype(str)\n",
    "        data.sort_values('frame_id', inplace=True)\n",
    "\n",
    "\n",
    "        # Mean Position\n",
    "        data['pos_x'] = data['pos_x'] - data['pos_x'].mean()\n",
    "        data['pos_y'] = data['pos_y'] - data['pos_y'].mean()\n",
    "\n",
    "        max_timesteps = data['frame_id'].max()\n",
    "\n",
    "        scene = Scene(timesteps=max_timesteps+1, dt=dt, name=desired_source + \"_\" + data_class, aug_func=None) # aug_func=augment if data_class == 'train' else\n",
    "\n",
    "        for node_id in pd.unique(data['node_id']):\n",
    "\n",
    "            node_df = data[data['node_id'] == node_id]\n",
    "            assert np.all(np.diff(node_df['frame_id']) == 1)\n",
    "\n",
    "            node_values = node_df[['pos_x', 'pos_y']].values\n",
    "\n",
    "            if node_values.shape[0] < 2:\n",
    "                continue\n",
    "\n",
    "            new_first_idx = node_df['frame_id'].iloc[0]\n",
    "\n",
    "            x = node_values[:, 0]\n",
    "            y = node_values[:, 1]\n",
    "            vx = derivative_of(x, scene.dt)\n",
    "            vy = derivative_of(y, scene.dt)\n",
    "            ax = derivative_of(vx, scene.dt)\n",
    "            ay = derivative_of(vy, scene.dt)\n",
    "\n",
    "            data_dict = {('position', 'x'): x,\n",
    "                         ('position', 'y'): y,\n",
    "                         ('velocity', 'x'): vx,\n",
    "                         ('velocity', 'y'): vy,\n",
    "                         ('acceleration', 'x'): ax,\n",
    "                         ('acceleration', 'y'): ay}\n",
    "\n",
    "            node_data = pd.DataFrame(data_dict, columns=data_columns)\n",
    "            node = Node(node_type=env.NodeType.PEDESTRIAN, node_id=node_id, data=node_data)\n",
    "            node.first_timestep = new_first_idx\n",
    "\n",
    "            scene.nodes.append(node)\n",
    "\n",
    "        scenes.append(scene)\n",
    "        counter += 1\n",
    "        #     if counter > 100:\n",
    "        #         break\n",
    "        #print(f'Processed {len(scenes):.2f} scene for data class {data_class}')\n",
    "\n",
    "    env.scenes = scenes\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ac5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9825358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946a298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--conf CONF] [--debug]\n",
      "                             [--preprocess_workers PREPROCESS_WORKERS]\n",
      "                             [--offline_scene_graph OFFLINE_SCENE_GRAPH]\n",
      "                             [--dynamic_edges DYNAMIC_EDGES]\n",
      "                             [--edge_state_combine_method EDGE_STATE_COMBINE_METHOD]\n",
      "                             [--edge_influence_combine_method EDGE_INFLUENCE_COMBINE_METHOD]\n",
      "                             [--edge_addition_filter EDGE_ADDITION_FILTER [EDGE_ADDITION_FILTER ...]]\n",
      "                             [--edge_removal_filter EDGE_REMOVAL_FILTER [EDGE_REMOVAL_FILTER ...]]\n",
      "                             [--override_attention_radius OVERRIDE_ATTENTION_RADIUS]\n",
      "                             [--incl_robot_node] [--map_encoding] [--augment]\n",
      "                             [--node_freq_mult_train] [--node_freq_mult_eval]\n",
      "                             [--scene_freq_mult_train]\n",
      "                             [--scene_freq_mult_eval] [--scene_freq_mult_viz]\n",
      "                             [--no_edge_encoding] [--data_dir DATA_DIR]\n",
      "                             [--train_data_dict TRAIN_DATA_DICT]\n",
      "                             [--eval_data_dict EVAL_DATA_DICT]\n",
      "                             [--log_dir LOG_DIR] [--log_tag LOG_TAG]\n",
      "                             [--device DEVICE] [--eval_device EVAL_DEVICE]\n",
      "                             [--train_epochs TRAIN_EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--eval_batch_size EVAL_BATCH_SIZE]\n",
      "                             [--k_eval K_EVAL] [--seed SEED]\n",
      "                             [--eval_every EVAL_EVERY] [--vis_every VIS_EVERY]\n",
      "                             [--save_every SAVE_EVERY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/user/.local/share/jupyter/runtime/kernel-130bf887-a92d-4694-bf2a-220f41f7ccbd.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim, utils\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import dill\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import visualization\n",
    "import evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from argument_parser import args\n",
    "from model.model_registrar import ModelRegistrar\n",
    "from model.model_utils import cyclical_lr\n",
    "from model.dataset import EnvironmentDataset, collate\n",
    "from tensorboardX import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ecebea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.trajectron import Trajectron\n",
    "from model.model_registrar import ModelRegistrar\n",
    "import json \n",
    "\n",
    "log_writer = None\n",
    "\n",
    "model_registrar = ModelRegistrar('', 'cuda:0')\n",
    "conf ='../experiments/pedestrians/models/argo/config.json'\n",
    "with open(conf, 'r', encoding='utf-8') as conf_json:\n",
    "    hyperparams = json.load(conf_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(args.log_dir, 'int_ee')\n",
    "model_registrar = ModelRegistrar(model_dir, args.eval_device)\n",
    "model_registrar.load_models(iter_num=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcb68af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ../experiments/argoverse/models/models_15_Jan_2022_21_03_31_argo_first/model_registrar-12.pt\n",
      "Loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_registrar.model_dir = '../experiments/argoverse/models/models_15_Jan_2022_21_03_31_argo_first'\n",
    "model_registrar.load_models(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c7a7f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127654"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model_registrar.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29bd0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectron = Trajectron(model_registrar,\n",
    "                        hyperparams,\n",
    "                        log_writer,\n",
    "                        'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b58dcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectron.node_models_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trajectron",
   "language": "python",
   "name": "trajectron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
